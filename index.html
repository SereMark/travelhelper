<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black">
<title>Vision AI - Audio First</title>
<style>
:root {
    --safe-area-inset-top: env(safe-area-inset-top, 20px);
    --safe-area-inset-bottom: env(safe-area-inset-bottom, 20px);
}
* {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
    -webkit-tap-highlight-color: transparent;
    -webkit-user-select: none;
    user-select: none;
}
body {
    font-family: -apple-system, system-ui, sans-serif;
    background: #000;
    color: #fff;
    overflow: hidden;
    position: fixed;
    width: 100%;
    height: 100%;
}
#camera {
    width: 100%;
    height: 100%;
    object-fit: cover;
    position: absolute;
    top: 0;
    left: 0;
    z-index: 1;
}

/* --- CORE UI --- */
.main-controls {
    position: fixed;
    bottom: 30px;
    left: 50%;
    transform: translateX(-50%);
    display: flex;
    gap: 20px;
    align-items: center;
    z-index: 10;
}
.toggle-btn {
    width: 70px;
    height: 70px;
    border-radius: 50%;
    background: #007AFF;
    border: 3px solid #fff;
    cursor: pointer;
    transition: all 0.2s;
    box-shadow: 0 4px 12px rgba(0,0,0,0.3);
}
.toggle-btn:active {
    transform: scale(0.95);
}
.toggle-btn.active {
    background: #FF3B30;
    animation: pulse 1.5s infinite;
}
@keyframes pulse {
    0%, 100% { box-shadow: 0 0 0 0 rgba(255, 59, 48, 0.7); }
    50% { box-shadow: 0 0 0 15px rgba(255, 59, 48, 0); }
}
.settings-btn {
    width: 50px;
    height: 50px;
    border-radius: 50%;
    background: rgba(255,255,255,0.2);
    backdrop-filter: blur(10px);
    -webkit-backdrop-filter: blur(10px);
    border: none;
    font-size: 24px;
    cursor: pointer;
    box-shadow: 0 4px 12px rgba(0,0,0,0.3);
}

.zoom-control {
    position: fixed;
    right: 20px;
    top: 50%;
    transform: translateY(-50%);
    background: rgba(255,255,255,0.1);
    backdrop-filter: blur(10px);
    border-radius: 20px;
    padding: 10px;
    z-index: 10;
    display: none; /* Hidden by default, shown via JS */
}
.zoom-control.show {
    display: block;
}
.zoom-slider {
    writing-mode: bt-lr;
    -webkit-appearance: slider-vertical;
    width: 40px;
    height: 200px;
    background: transparent;
    outline: none;
    cursor: pointer;
}

/* --- SETTINGS PANEL --- */
.settings {
    position: fixed;
    inset: 0;
    background: #121212;
    transform: translateX(100%);
    transition: transform 0.4s cubic-bezier(0.19, 1, 0.22, 1);
    z-index: 1000;
    display: flex;
    flex-direction: column;
}
.settings.open {
    transform: translateX(0);
}
.settings-header {
    padding: 15px 20px;
    padding-top: var(--safe-area-inset-top);
    display: flex;
    justify-content: space-between;
    align-items: center;
    border-bottom: 1px solid rgba(255,255,255,0.1);
    flex-shrink: 0;
}
.settings h2 {
    font-size: 24px;
}
.close-btn {
    background: none;
    border: none;
    color: #888;
    font-size: 28px;
    cursor: pointer;
}
.settings-content {
    padding: 20px;
    overflow-y: auto;
    flex-grow: 1;
    -webkit-overflow-scrolling: touch;
}
.section {
    margin-bottom: 25px;
}
.section-title {
    font-size: 13px;
    opacity: 0.5;
    text-transform: uppercase;
    letter-spacing: 1px;
    margin-bottom: 10px;
}
.input-group {
    background: #222;
    padding: 12px 16px;
    border-radius: 10px;
    margin-bottom: 10px;
    display: flex;
    flex-direction: column;
    align-items: flex-start;
}
.input-group label {
    font-size: 14px;
    opacity: 0.7;
    margin-bottom: 8px;
}
.input-group input, .input-group select {
    width: 100%;
    background: none;
    border: none;
    color: #fff;
    font-size: 16px;
    outline: none;
    font-family: inherit;
}
.input-group select {
    appearance: none;
    -webkit-appearance: none;
}

/* --- LOGS SECTION --- */
.logs-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 10px;
}
.clear-logs-btn {
    background: rgba(255,59,48,0.2);
    border: none;
    border-radius: 8px;
    color: #FF453A;
    padding: 6px 12px;
    font-size: 13px;
    cursor: pointer;
}
.log-container {
    background: #000;
    border: 1px solid #333;
    border-radius: 12px;
    padding: 16px;
    font-family: 'SF Mono', 'Monaco', monospace;
    font-size: 11px;
    line-height: 1.6;
    height: 300px; /* Fixed height for consistent layout */
    overflow-y: auto;
    -webkit-overflow-scrolling: touch;
}
.log-entry {
    margin-bottom: 4px;
    word-break: break-all;
}
.log-time {
    opacity: 0.4;
    padding-right: 8px;
}
.log-entry.error { color: #FF453A; }
.log-entry.success { color: #32D74B; }
.log-entry.info { color: #64D2FF; }
.log-entry.warning { color: #FFD60A; }
</style>
</head>
<body>

<video id="camera" playsinline autoplay muted></video>

<div class="main-controls">
    <button class="toggle-btn" id="toggleBtn"></button>
    <button class="settings-btn" id="settingsBtn">⚙️</button>
</div>

<div class="zoom-control" id="zoomControl">
    <input type="range" class="zoom-slider" id="zoomSlider">
</div>

<div class="settings" id="settingsPanel">
    <div class="settings-header">
        <h2>Settings</h2>
        <button class="close-btn" id="closeBtn">×</button>
    </div>
    <div class="settings-content">
        <div class="section">
            <h3 class="section-title">API Configuration</h3>
            <div class="input-group"><label>OpenAI API Key</label><input type="password" id="openaiKey" placeholder="sk-..."></div>
            <div class="input-group"><label>Google AI API Key</label><input type="password" id="geminiKey" placeholder="AIza..."></div>
        </div>
        <div class="section">
            <h3 class="section-title">Device Settings</h3>
            <div class="input-group"><label>Camera</label><select id="cameraSelect"><option>Loading...</option></select></div>
        </div>
        <div class="section">
            <div class="logs-header">
                <h3 class="section-title">Debug Log</h3>
                <button class="clear-logs-btn" id="clearLogsBtn">Clear</button>
            </div>
            <div class="log-container" id="logContainer"></div>
        </div>
    </div>
</div>

<script>
class VisionAudioSolver {
    constructor() {
        this.state = 'IDLE';
        this.dom = this._getDomElements();
        this.settings = this._loadSettings();
        this.cameraStream = null;
        this.videoTrack = null;
    }

    // --- 1. INITIALIZATION & SETUP ---

    _getDomElements() {
        return {
            camera: document.getElementById('camera'),
            toggleBtn: document.getElementById('toggleBtn'),
            settingsBtn: document.getElementById('settingsBtn'),
            zoomControl: document.getElementById('zoomControl'),
            zoomSlider: document.getElementById('zoomSlider'),
            settingsPanel: document.getElementById('settingsPanel'),
            closeBtn: document.getElementById('closeBtn'),
            openaiKey: document.getElementById('openaiKey'),
            geminiKey: document.getElementById('geminiKey'),
            cameraSelect: document.getElementById('cameraSelect'),
            logContainer: document.getElementById('logContainer'),
            clearLogsBtn: document.getElementById('clearLogsBtn'),
        };
    }

    _loadSettings() {
        return {
            openai: localStorage.getItem('vision_solver_openai') || '',
            gemini: localStorage.getItem('vision_solver_gemini') || '',
            cameraId: localStorage.getItem('vision_solver_camera') || '',
        };
    }

    async initialize() {
        this._log('App Initializing...');
        this._bindEvents();
        try {
            const cameraDevices = await this._enumerateCameras();
            let deviceIdToUse = this.settings.cameraId;

            if (!deviceIdToUse || !cameraDevices.some(d => d.deviceId === deviceIdToUse)) {
                this._log('Saved camera not found or not set. Using first available camera.', 'warning');
                deviceIdToUse = cameraDevices[0]?.deviceId;
                if (deviceIdToUse) {
                    this.settings.cameraId = deviceIdToUse;
                    localStorage.setItem('vision_solver_camera', deviceIdToUse);
                }
            }

            if (!deviceIdToUse) throw new Error("No camera devices were found.");
            
            await this._startCamera(deviceIdToUse);
            this._log('App Ready.', 'success');
            this._setState('IDLE');
        } catch (err) {
            this._handleError(err.message);
        }
    }
    
    _bindEvents() {
        this.dom.toggleBtn.addEventListener('click', () => this.toggleScan());
        this.dom.settingsBtn.addEventListener('click', () => this.openSettings());
        this.dom.closeBtn.addEventListener('click', () => this.saveAndCloseSettings());
        this.dom.clearLogsBtn.addEventListener('click', () => {
            this.dom.logContainer.innerHTML = '';
            this._log("Logs cleared.");
        });
        this.dom.zoomSlider.addEventListener('input', (e) => this._setZoom(e.target.value));
    }

    // --- 2. STATE & CORE WORKFLOW ---

    _setState(newState) {
        this.state = newState;
        this._log(`State changed to: ${newState}`, 'info');
        this.dom.toggleBtn.classList.toggle('active', newState !== 'IDLE' && newState !== 'ERROR');
    }

    toggleScan() {
        if (this.state === 'IDLE' || this.state === 'ERROR') {
            this.startScan();
        } else {
            speechSynthesis.cancel();
            this._speak("Scan cancelled.");
            this._setState('IDLE');
        }
    }

    async startScan() {
        if (this.state !== 'IDLE' && this.state !== 'ERROR') return;
        
        if (!this.settings.openai || !this.settings.gemini) {
            return this._handleError("API Keys are not set in settings.");
        }

        this._setState('CAPTURING');
        try {
            const imageData = this._captureImage();

            this._setState('EXTRACTING');
            const extractedQuestions = await this._performExtractionWithRetries(imageData);
            
            if (extractedQuestions.length === 0) {
                throw new Error("No questions found in the image after all attempts.");
            }
            this._log(`Extraction successful. Found ${extractedQuestions.length} question(s).`, 'success');

            this._setState('SOLVING_BATCH');
            this._speak(`Solving with Gemini 2.5 Pro`);
            const solvedAnswers = await this._api.gemini.solveBatch(extractedQuestions, this.settings.gemini);

            let speechText = '';
            extractedQuestions.forEach(q => {
                const answer = solvedAnswers[q.number] || 'Not found';
                this._log(`Q#${q.number} -> Answer: ${answer}`, 'success');
                speechText += `Answer for question ${q.number}: ${answer.split(',').join(', ')}. `;
            });
            speechText += "Scan complete.";
            
            this._speak(speechText);
            this._setState('IDLE');

        } catch (err) {
            this._handleError(err.message);
        }
    }

    async _performExtractionWithRetries(imageData) {
        const MAX_ATTEMPTS = 3;
        for (let attempt = 1; attempt <= MAX_ATTEMPTS; attempt++) {
            this._speak(attempt === 1 ? "Extracting questions" : "Retrying extraction...");
            this._log(`Extraction attempt ${attempt}/${MAX_ATTEMPTS}...`);
            
            const { questions, finishDetails } = await this._api.openai.extract(imageData, this.settings.openai);

            if (questions.length > 0) {
                return questions; // Success
            }

            const reason = finishDetails?.type || 'unknown';
            this._log(`Attempt ${attempt} failed. Finish reason: ${reason}`, 'warning');
            
            if (reason === 'content_filter') {
                this._speak("Image flagged by content filter.");
            }
            
            if (reason === 'stop') {
                this._log('AI stopped cleanly but found no content. Halting retries.', 'warning');
                break;
            }

            if (attempt < MAX_ATTEMPTS) {
                await new Promise(resolve => setTimeout(resolve, 1000)); // Wait before retry
            }
        }
        return []; // Return empty if all attempts fail
    }

    _handleError(errorMessage) {
        this._log(errorMessage, 'error');
        this._speak(`Error. Check the logs.`);
        this._setState('ERROR');
    }

    // --- 3. HARDWARE & DEVICE CONTROLS ---

    async _enumerateCameras() {
        this._log("Enumerating cameras...");
        await navigator.mediaDevices.getUserMedia({video: true});
        const devices = await navigator.mediaDevices.enumerateDevices();
        const videoDevices = devices.filter(d => d.kind === 'videoinput');

        if (videoDevices.length > 0) {
            this.dom.cameraSelect.innerHTML = videoDevices.map(d => `<option value="${d.deviceId}">${d.label || `Camera ${videoDevices.indexOf(d)+1}`}</option>`).join('');
            this._log(`Found ${videoDevices.length} cameras.`, 'success');
        } else {
            this._log("No cameras found.", 'error');
        }
        return videoDevices;
    }

    async _startCamera(deviceId) {
        this._log(`Attempting to start camera: ${deviceId ? deviceId.substring(0,8) : 'Default'}`);
        if (this.cameraStream) {
            this.cameraStream.getTracks().forEach(track => track.stop());
        }
        try {
            const constraints = { video: { deviceId: { exact: deviceId }, width: { ideal: 1920 }, height: { ideal: 1080 } } };
            this.cameraStream = await navigator.mediaDevices.getUserMedia(constraints);
            this.dom.camera.srcObject = this.cameraStream;
            await this.dom.camera.play();
            this.videoTrack = this.cameraStream.getVideoTracks()[0];
            this._setupZoom();
            this._log("Camera started successfully.", "success");
        } catch (err) {
            throw new Error(`Failed to start camera: ${err.name}`);
        }
    }

    _setupZoom() {
        if (!this.videoTrack?.getCapabilities) {
            return this.dom.zoomControl.classList.remove('show');
        }
        const capabilities = this.videoTrack.getCapabilities();
        if (capabilities.zoom) {
            this._log(`Zoom supported: [${capabilities.zoom.min}-${capabilities.zoom.max}]`, 'info');
            this.dom.zoomSlider.min = capabilities.zoom.min;
            this.dom.zoomSlider.max = capabilities.zoom.max;
            this.dom.zoomSlider.step = capabilities.zoom.step || 0.1;
            this.dom.zoomSlider.value = this.videoTrack.getSettings()?.zoom || 1;
            this.dom.zoomControl.classList.add('show');
        } else {
            this.dom.zoomControl.classList.remove('show');
            this._log("Zoom not supported by this camera.", 'warning');
        }
    }
    
    async _setZoom(value) {
        if (!this.videoTrack || !this.videoTrack.applyConstraints) return;
        try {
            await this.videoTrack.applyConstraints({ advanced: [{ zoom: parseFloat(value) }] });
        } catch (err) {
            this._log(`Zoom failed: ${err.message}`, 'error');
        }
    }

    // --- 4. HELPERS (CAPTURE, SPEECH, API, LOGGING) ---

    _captureImage() {
        this._log("Capturing image...");
        const canvas = document.createElement('canvas');
        canvas.width = this.dom.camera.videoWidth;
        canvas.height = this.dom.camera.videoHeight;
        canvas.getContext('2d').drawImage(this.dom.camera, 0, 0);
        this._log("Image capture complete.", "success");
        return canvas.toDataURL('image/jpeg', 0.9);
    }

    _speak(text) {
        this._log(`Speaking: "${text}"`, 'info');
        if (!('speechSynthesis' in window)) return this._log("Speech synthesis not supported.", 'error');
        speechSynthesis.cancel();
        const utterance = new SpeechSynthesisUtterance(text);
        utterance.rate = 1.0;
        speechSynthesis.speak(utterance);
    }

    _log(message, type = 'log') {
        const timestamp = new Date().toLocaleTimeString([], { hour: '2-digit', minute: '2-digit', second: '2-digit'});
        const consoleMessage = `[${timestamp}] ${message}`;
        
        if (type === 'error') console.error(consoleMessage);
        else if (type === 'warning') console.warn(consoleMessage);
        else console.log(consoleMessage);
        
        const entry = document.createElement('div');
        entry.className = `log-entry ${type}`;
        entry.innerHTML = `<span class="log-time">[${timestamp}]</span> ${message}`;
        this.dom.logContainer.appendChild(entry);
        this.dom.logContainer.scrollTop = this.dom.logContainer.scrollHeight;
    }

    _api = {
        openai: {
            extract: async (imageData, apiKey) => {
                this._log("Calling OpenAI GPT-4o...");
                const prompt = `You are an expert at analyzing images. Your task is to find all distinct multiple-choice questions in the provided image. Your entire response MUST be a single, valid JSON array. Each object in the array must have a "number" (integer) and a "text" (string) key. If you cannot find any questions, you MUST return an empty array []. Do not include any other text, explanations, or markdown formatting. Example: [{"number": 21, "text": "What is...?"}, {"number": 22, "text": "Which of..."}]`;
                
                const response = await fetch('https://api.openai.com/v1/chat/completions', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json', 'Authorization': `Bearer ${apiKey}` },
                    body: JSON.stringify({
                        model: 'gpt-4o',
                        messages: [{ role: 'user', content: [{ type: 'text', text: prompt }, { type: 'image_url', image_url: { url: imageData, detail: 'high' } }] }],
                        response_format: { type: "json_object" }
                    })
                });
                
                if (!response.ok) {
                    let errorBody;
                    try { errorBody = await response.json(); } catch (e) { throw new Error(`HTTP Error ${response.status} ${response.statusText}`); }
                    const message = errorBody.error?.message || JSON.stringify(errorBody);
                    throw new Error(`OpenAI API Error: ${response.status} - ${message}`);
                }

                const data = await response.json();
                
                // *** DEFINITIVE FIX: Safely access content and return finish details ***
                const rawContent = data?.choices?.[0]?.message?.content;
                const finishDetails = data?.choices?.[0]?.finish_details || { type: 'unknown' };
                
                if (!rawContent) {
                    this._log("AI response content is null or empty.", 'warning');
                    return { questions: [], finishDetails };
                }

                this._log(`Received raw content from OpenAI: ${rawContent}`, 'info');
                const jsonMatch = rawContent.match(/{[\s\S]*}|\[[\s\S]*\]/);

                if (!jsonMatch) {
                    this._log("Could not find a valid JSON block in the AI response.", 'warning');
                    return { questions: [], finishDetails };
                }
                
                const jsonString = jsonMatch[0];
                let parsedContent;
                try {
                    parsedContent = JSON.parse(jsonString);
                } catch(e) {
                    this._log(`Failed to parse extracted JSON string: ${e.message}`, 'error');
                    return { questions: [], finishDetails }; // Parsing failed, so it's an empty result for this attempt
                }

                if (Array.isArray(parsedContent)) {
                    return { questions: parsedContent, finishDetails };
                }
                if (typeof parsedContent === 'object' && parsedContent !== null) {
                    const arrayValue = Object.values(parsedContent).find(v => Array.isArray(v));
                    if (arrayValue) return { questions: arrayValue, finishDetails };
                }
                
                // If we reach here, we got valid JSON, but it wasn't in the expected format.
                return { questions: [], finishDetails };
            }
        },
        gemini: {
            solveBatch: async (questions, apiKey) => {
                this._log("Calling Gemini 2.5 Pro to solve batch...");
                const formattedQuestions = questions.map(q => `Question #${q.number}:\n${q.text}`).join('\n\n---\n\n');
                const prompt = `You are an expert test-taker. Below are several multiple-choice questions. Solve each one. Return a single JSON object where keys are the question numbers (as strings) and values are the correct letter choices (as strings, e.g., "A" or "B,D"). Example response: {"21": "A", "22": "C,D"}. Respond ONLY with the JSON object. Questions: ${formattedQuestions}`;
                
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro:generateContent?key=${apiKey}`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        contents: [{ parts: [{ text: prompt }] }],
                        generationConfig: { responseMimeType: "application/json", temperature: 0.0 }
                    })
                });

                if (!response.ok) {
                    let errorBody;
                    try { errorBody = await response.json(); } catch (e) { throw new Error(`HTTP Error ${response.status} ${response.statusText}`); }
                    const message = errorBody.error?.message || JSON.stringify(errorBody);
                    throw new Error(`Gemini API Error: ${response.status} - ${message}`);
                }

                const data = await response.json();
                this._log("Gemini batch solve successful.", 'success');
                return JSON.parse(data.candidates[0].content.parts[0].text);
            }
        }
    };
    
    // --- 5. SETTINGS PANEL LOGIC ---
    openSettings() {
        this._log("Opening settings...");
        this.dom.openaiKey.value = this.settings.openai;
        this.dom.geminiKey.value = this.settings.gemini;
        this.dom.cameraSelect.value = this.settings.cameraId;
        this.dom.settingsPanel.classList.add('open');
    }

    async saveAndCloseSettings() {
        this._log("Saving settings and closing...");
        const newCameraId = this.dom.cameraSelect.value;
        this.settings.openai = this.dom.openaiKey.value.trim();
        this.settings.gemini = this.dom.geminiKey.value.trim();

        localStorage.setItem('vision_solver_openai', this.settings.openai);
        localStorage.setItem('vision_solver_gemini', this.settings.gemini);
        
        if (this.settings.cameraId !== newCameraId) {
            this._log("Camera selection changed.", 'info');
            this.settings.cameraId = newCameraId;
            localStorage.setItem('vision_solver_camera', this.settings.cameraId);
            await this._startCamera(this.settings.cameraId);
        }
        
        this.dom.settingsPanel.classList.remove('open');
    }
}

// --- App Entry Point ---
document.addEventListener('DOMContentLoaded', () => {
    const app = new VisionAudioSolver();
    app.initialize();
});
</script>
</body>
</html>